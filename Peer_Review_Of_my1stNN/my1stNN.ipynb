{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (50000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4b20775c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from preprocessed_mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "print(X_train.shape, y_train.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "-----\n",
      "1 round training loss = 4.4645, validation loss = 6.71833\n",
      "1 round training accuracy = 0.85, validation accuracy = 0.8308\n",
      "test loss = 6.82312 \n",
      "test accuracy = 0.824\n",
      "3 seconds spent\n",
      "-----\n",
      "11 round training loss = 0.21678, validation loss = 0.458691\n",
      "11 round training accuracy = 0.98, validation accuracy = 0.9519\n",
      "test loss = 0.453679 \n",
      "test accuracy = 0.9517\n",
      "20 seconds spent\n",
      "-----\n",
      "21 round training loss = 0.134664, validation loss = 0.225362\n",
      "21 round training accuracy = 0.98, validation accuracy = 0.9671\n",
      "test loss = 0.211766 \n",
      "test accuracy = 0.9711\n",
      "36 seconds spent\n",
      "-----\n",
      "31 round training loss = 0.181817, validation loss = 0.335953\n",
      "31 round training accuracy = 0.99, validation accuracy = 0.9669\n",
      "test loss = 0.279487 \n",
      "test accuracy = 0.9698\n",
      "52 seconds spent\n",
      "-----\n",
      "41 round training loss = 0.273232, validation loss = 0.313522\n",
      "41 round training accuracy = 0.97, validation accuracy = 0.972\n",
      "test loss = 0.312418 \n",
      "test accuracy = 0.9685\n",
      "69 seconds spent\n",
      "-----\n",
      "51 round training loss = 0.079407, validation loss = 0.304893\n",
      "51 round training accuracy = 1, validation accuracy = 0.9743\n",
      "test loss = 0.305024 \n",
      "test accuracy = 0.9708\n",
      "85 seconds spent\n",
      "-----\n",
      "61 round training loss = 0.131457, validation loss = 0.345802\n",
      "61 round training accuracy = 0.99, validation accuracy = 0.9694\n",
      "test loss = 0.311968 \n",
      "test accuracy = 0.9683\n",
      "102 seconds spent\n",
      "-----\n",
      "71 round training loss = 0.204579, validation loss = 0.306511\n",
      "71 round training accuracy = 0.99, validation accuracy = 0.9692\n",
      "test loss = 0.285387 \n",
      "test accuracy = 0.9714\n",
      "119 seconds spent\n",
      "-----\n",
      "81 round training loss = 0.07531, validation loss = 0.309293\n",
      "81 round training accuracy = 1, validation accuracy = 0.9702\n",
      "test loss = 0.310914 \n",
      "test accuracy = 0.9714\n",
      "135 seconds spent\n",
      "-----\n",
      "91 round training loss = 0.0893185, validation loss = 0.313524\n",
      "91 round training accuracy = 0.99, validation accuracy = 0.9697\n",
      "test loss = 0.289283 \n",
      "test accuracy = 0.9717\n",
      "152 seconds spent\n",
      "-----\n",
      "101 round training loss = 0.102492, validation loss = 0.351028\n",
      "101 round training accuracy = 0.99, validation accuracy = 0.9673\n",
      "test loss = 0.329349 \n",
      "test accuracy = 0.9677\n",
      "168 seconds spent\n",
      "-----\n",
      "111 round training loss = 0.072883, validation loss = 0.386816\n",
      "111 round training accuracy = 1, validation accuracy = 0.963\n",
      "test loss = 0.354725 \n",
      "test accuracy = 0.9622\n",
      "185 seconds spent\n",
      "-----\n",
      "121 round training loss = 0.103655, validation loss = 0.326516\n",
      "121 round training accuracy = 0.99, validation accuracy = 0.9689\n",
      "test loss = 0.320651 \n",
      "test accuracy = 0.9682\n",
      "201 seconds spent\n",
      "-----\n",
      "131 round training loss = 0.0732713, validation loss = 0.335896\n",
      "131 round training accuracy = 1, validation accuracy = 0.9681\n",
      "test loss = 0.313607 \n",
      "test accuracy = 0.9688\n",
      "219 seconds spent\n",
      "-----\n",
      "141 round training loss = 0.0775091, validation loss = 0.322573\n",
      "141 round training accuracy = 0.99, validation accuracy = 0.9725\n",
      "test loss = 0.296473 \n",
      "test accuracy = 0.9713\n",
      "237 seconds spent\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "NUM_OF_CATEGORY = 10\n",
    "NUM_OF_NEURON_L1 = 300\n",
    "NUM_OF_DENSE_L = 50\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_OF_EPOCH = 200\n",
    "BATCH_SIZE = 100\n",
    "REG_LAMBDA = 0.00001\n",
    "\n",
    "def reshape_X(X):\n",
    "    return np.reshape(X, [X.shape[0], X.shape[1] * X.shape[2]])\n",
    "\n",
    "def one_hot_encoding(Y):\n",
    "    result = np.zeros((Y.shape[0], 10))\n",
    "    for i in range(Y.shape[0]):\n",
    "        y = Y[i]\n",
    "        result[i][y] = 1.0\n",
    "    return result\n",
    "\n",
    "# Shuffle the data of X_train and y_train to make it random\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "shuffled_X_train, shuffled_Y_train = shuffle(X_train, y_train, random_state=0)\n",
    "\n",
    "# reshaped the X data to a 1-D array\n",
    "X_train_reshaped = reshape_X(shuffled_X_train)\n",
    "X_val_reshaped = reshape_X(X_val)\n",
    "X_test_reshaped = reshape_X(X_test)\n",
    "\n",
    "# one hot encoding the val and test label\n",
    "y_val_reshaped = one_hot_encoding(y_val)\n",
    "y_test_reshaped = one_hot_encoding(y_test)\n",
    "\n",
    "layer1_input_count = X_train_reshaped.shape[1]\n",
    "num_of_batch = int(X_train_reshaped.shape[0]/BATCH_SIZE)\n",
    "\n",
    "# construct the forward propagation\n",
    "\n",
    "input_X = tf.placeholder('float32', shape=[None, layer1_input_count], name=\"input_X\")\n",
    "input_Y = tf.placeholder('float32', shape=[None, NUM_OF_CATEGORY], name=\"input_Y\")\n",
    "\n",
    "layer1_weight = tf.Variable(initial_value = np.random.random((layer1_input_count, NUM_OF_NEURON_L1)), dtype=tf.float32, name=\"l1_weight\")\n",
    "layer1_bias = tf.Variable(initial_value = tf.constant(0.1, shape= [NUM_OF_NEURON_L1]), dtype=tf.float32, name=\"l1_bias\")\n",
    "\n",
    "# Calculate the hidden layer\n",
    "layer1_neuron = tf.nn.relu(tf.matmul(input_X, layer1_weight) + layer1_bias, name=\"l1_neuron\")\n",
    "\n",
    "\n",
    "dense_layer = tf.Variable(initial_value = np.random.random((NUM_OF_NEURON_L1, NUM_OF_CATEGORY)), dtype=tf.float32, name=\"dense_weight\")\n",
    "dense_bias = tf.Variable(initial_value=tf.constant(0.1, shape=[NUM_OF_CATEGORY]), dtype=tf.float32, name=\"dense_bias\")\n",
    "\n",
    "z = tf.matmul(layer1_neuron, dense_layer) + dense_bias\n",
    "\n",
    "# Get the prediction\n",
    "prediction = tf.nn.softmax(z)\n",
    "correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(input_Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "# Get the loss = cross_entropy + l2_regularization\n",
    "regularization = REG_LAMBDA * (tf.nn.l2_loss(layer1_weight) + tf.nn.l2_loss(dense_layer))\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=input_Y,logits=z))\n",
    "\n",
    "loss = cross_entropy + regularization\n",
    "#loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=input_Y,logits=z))\n",
    "# Get the optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(loss)\n",
    "\n",
    "\n",
    "# Start training\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "iterations = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(\"Start training...\")\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    iteration = 0\n",
    "    for i in range(NUM_OF_EPOCH):\n",
    "        for j in range(num_of_batch):\n",
    "            start_index = j * BATCH_SIZE\n",
    "            end_index = start_index + BATCH_SIZE\n",
    "            X_batch = X_train_reshaped[start_index:end_index,].astype(np.float32)\n",
    "            y_batch = one_hot_encoding(shuffled_Y_train[start_index:end_index,])\n",
    "            _, train_loss, train_accuracy = sess.run([optimizer, loss, accuracy], feed_dict = {input_X: X_batch, input_Y : y_batch })\n",
    "            iteration += 1  \n",
    "        if i%10 == 1:\n",
    "            val_loss, val_accuracy = sess.run([loss, accuracy], feed_dict = {input_X: X_val_reshaped, input_Y : y_val_reshaped})\n",
    "            print(\"-----\")\n",
    "            print(\"%d round training loss = %g, validation loss = %g\" % (i, train_loss, val_loss))\n",
    "            print(\"%d round training accuracy = %g, validation accuracy = %g\" % (i, train_accuracy, val_accuracy))\n",
    "            test_loss, test_accuracy = sess.run([loss, accuracy], feed_dict = {input_X:X_test_reshaped, input_Y :y_test_reshaped})\n",
    "            print(\"test loss = %g \" % (test_loss))\n",
    "            print(\"test accuracy = %g\" % (test_accuracy))\n",
    "            time_spent = time.time() - start_time\n",
    "            print(\"%d seconds spent\" % time_spent)\n",
    "            iterations.append(iteration)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            test_losses.append(test_loss)\n",
    "            if (time_spent >= 280 or val_accuracy >= 0.98):\n",
    "                print(\"Now time runs out or the accuracy is good enough\")\n",
    "                break\n",
    "    time_spent = time.time() - start_time\n",
    "    print(\"%d total seconds spent\" % time_spent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(iterations, train_losses, label=\"Training Loss\")\n",
    "plt.plot(iterations, val_losses, label=\"Validation Loss\")\n",
    "plt.plot(iterations, test_losses, label=\"Test Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
